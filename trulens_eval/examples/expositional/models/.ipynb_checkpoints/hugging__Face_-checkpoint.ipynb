{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afda259b-6774-40bf-918f-1930d82d4b0f",
   "metadata": {},
   "source": [
    "## Evaluating RAG of e5 Embedding and Mistral 8x7 as LLM by HHEM evaluator\r\n",
    "\r\n",
    "In this quickstart, you'll learn to evaluate and create RAG using Hugging Face models using:\r\n",
    "\r\n",
    "1. **Intfloat Multilingual-e5-large-instruct** as the embedding function.\r\n",
    "2. **Mistral-8x7B** as the LLM (Large Language Model).\r\n",
    "3. **ChromaDB** as the vector database.\r\n",
    "4. **Vectra HHEM** as the evaluator.\r\n",
    "or.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ec330-6bd7-4711-857b-aa71fb002827",
   "metadata": {},
   "source": [
    "#!pip install langchain ,pip install langchain==0.0.354  ,pip install langchain-community==0.0.20 ,pip install langchain-core==0.1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8d8f9f9-1d63-40be-8d6f-96e4ba7d9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"trulens\\trulens_eval\")\n",
    "from trulens_eval.feedback.provider.hugs import Huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14b80ea-bc86-4045-8f68-a53dee91449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c746a-b3c2-44c2-a30e-215bd349084a",
   "metadata": {},
   "source": [
    "## Load your Data Documents Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecca5ca8-b36b-4f69-a672-a610f539b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./data/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54673c22-83ec-4063-92da-c9786d5395e9",
   "metadata": {},
   "source": [
    "## Split the DocumentTEXT into text Chunks to feed in ChromaDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09940fd-ffd7-4b53-ab99-746e19c310b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34e8b5-ad49-4760-82cc-07188a879849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "inference_api_key =getpass.getpass(\"Enter your HF Inference API Key:\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d607657-b583-4e43-b6d7-9c3d2634b0b7",
   "metadata": {},
   "source": [
    "## Add hugging face e5 embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a4d6a42-adc0-4f12-b546-42f4080bb3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embedding_function = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=inference_api_key, model_name=\"intfloat/multilingual-e5-large-instruct\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4cfb264-20d0-4b9f-aafd-a4f92a29c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(texts, embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a0469-b3a7-41bd-995f-1383b0666373",
   "metadata": {},
   "source": [
    "## Get relevant context Docs with respect to quert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c340d1b-bb20-4905-b32d-dbb6bd33115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is SpaceX\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "77b386a6-8610-43e8-baed-6c540bc35684",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = ''\n",
    "\n",
    "for doc in docs:\n",
    "    content += ''.join(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea25219-979e-49d7-8d7c-32026f9794ab",
   "metadata": {},
   "source": [
    "## Query the Mixtral 8X7B LLM adding context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec11c7f5-2768-4b4a-a406-b790d407b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "Dorsey responded to more questions, including one where he discussed Twitter founder Jack Dorsey’s view on Musk’s ownership of Twitter. When asked if there is anything Dorsey admires about Musk, he answered, “The people he sometimes listens to.”\n",
      "\n",
      "Musk said in a recent TED interview that he can’t guarantee free speech on Twitter, despite his claims it’s the “digital town square.” Dorsey said he’s not surprised\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def query_model(content, query):\n",
    "    url = \"https://api-inference.huggingface.co/models/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"inputs\": f\"answer the following question from the information given Question:{query}\\nInformation:{content}\\n\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        response_data = response.json()\n",
    "\n",
    "        # Extract the generated text from the response\n",
    "        generated_text = response_data[0]['generated_text']\n",
    "        # Remove the input text from the generated text\n",
    "        response_text = generated_text[len(data['inputs']):]\n",
    "\n",
    "        return response_text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "context_info =content\n",
    "question = \"what is SpaceX\"\n",
    "result = query_model(context_info, question)\n",
    "if result:\n",
    "    print(\"Response:\", result)\n",
    "else:\n",
    "    print(\"No response received.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d70fa-cc14-4014-ac13-db291446d75a",
   "metadata": {},
   "source": [
    "## Pass retrieval context docs and LLM reponce in HHEM evaluater to get relevance to get respoce between O to 1 depending on relevancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69db7453-1a42-485f-b657-0a88ac399587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258838027715683\n"
     ]
    }
   ],
   "source": [
    "huggingface_provider = Huggingface()\n",
    "score = huggingface_provider.hallucination_evaluator(result,content)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ed47d-6557-49a7-8512-d420cd01e743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
