{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cb7f49-112e-447e-a167-3caf2c84e395",
   "metadata": {},
   "source": [
    "# Vectra HHEM Evaluator\n",
    "In this quickstart you'll see how you can use HHEM evaluator feedback function from truLens in your application.\n",
    "The Vectra HHEM evaluator, or Hughes Hallucination Evaluation Model, is a tool used to determine if a summary produced by a large language model (LLM) might contain hallucinated information.\n",
    "\n",
    "It then analyzes both inputs and assigns a score indicating the probability of the summary containing hallucinations. The score ranges from 0 **no hallucination** to 1 **definitely hallucination**.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/models/vectra_hallucination_evaluation_model.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dac149-7bc9-4b58-8122-24b3e467c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"trulens/trulens_eval\")\n",
    "from trulens_eval.feedback.provider.hugs import Huggingface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b1ce4-090d-4564-a886-4aceca889529",
   "metadata": {},
   "source": [
    "### Import Langchain and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14b80ea-bc86-4045-8f68-a53dee91449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1896dd4-d0cd-4e45-8b64-558bf574cef6",
   "metadata": {},
   "source": [
    "## Load your data documenents and splits data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecca5ca8-b36b-4f69-a672-a610f539b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./data/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c64ba-a1d4-4557-a805-33f9cd3136cf",
   "metadata": {},
   "source": [
    "## load api keys and get OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a646906-e75c-425e-9b3c-464dd9ec51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2590161a-f08c-410a-ad05-2f8471046618",
   "metadata": {},
   "source": [
    "## Feed your DataChunks into VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a115b9-60d8-42c6-9b39-9997a6b7ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce3bd0-4f29-4e2d-8496-7587d156c01b",
   "metadata": {},
   "source": [
    "## Getting Relevant Context of the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d9de8c-9688-4214-a2c8-8e0a4cf0ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slack has evolved from a pure communications platform to one that enables companies to link directly to enterprise applications without having to resort to dreaded task switching. Today, at the Salesforce World Tour event in NYC, the company announced the next step in its platform’s evolution where it will be putting AI at the forefront of the user experience, making it easier to get information and build workflows.\n",
      "\n",
      "It’s important to note that these are announcements, and many of these features are not available yet.\n",
      "\n",
      "Rob Seaman says that rather than slapping on an AI cover, they are working to incorporate it in a variety of ways across the platform. That started last month with a small step, a partnership with OpenAI to bring a ChatGPT app into Slack, the first piece of a much broader vision for AI on the platform. That part is in beta at the moment.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Slack's plan for incorporating AI into its platform?\"\n",
    "docs = vectordb.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7d8a8-53d3-41e6-b5fd-85bc65332d8b",
   "metadata": {},
   "source": [
    "## combining All relevant docs in one String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b386a6-8610-43e8-baed-6c540bc35684",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = ''\n",
    "\n",
    "for doc in docs:\n",
    "    content += ''.join(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95200c-0fab-4cd3-a38b-4abe73c33b39",
   "metadata": {},
   "source": [
    "## Query llm(gpt 3.5) to generate answer/summary from retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0927f18-fb41-415a-8290-036e4e6286cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slack's plan for incorporating AI into its platform involves bringing AI natively into the user experience with SlackGPT. This will help customers work faster, communicate better, and learn faster. They are also working on AI-powered conversation summaries, writing assistance for composition, and generating Slack messages or content for linked Slack applications. The company is aiming to make it easier for users to get information and build workflows by leveraging AI technology directly within the Slack platform.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"We have provided context information below.\\n\"\n",
    "                       f\"---------------------\\n\"\n",
    "                       f\"{docs}\\n\"\n",
    "                       f\"---------------------\\n\"\n",
    "                       f\"Given this information, please answer the question: {query}\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response=response.choices[0].message.content\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c07881-395a-4d8b-9650-7936e21623f7",
   "metadata": {},
   "source": [
    "## Pass llm responce and retrival context to HHEM evaluator function\n",
    "HHEM takes two inputs:\n",
    "1. The summary/answer itself generated by LLM.\n",
    "2. The original source text that the LLM used to generate the summary/answer (retrieval context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69db7453-1a42-485f-b657-0a88ac399587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198882460594177\n"
     ]
    }
   ],
   "source": [
    "huggingface_provider = Huggingface()\n",
    "score = huggingface_provider.hallucination_evaluator(response,content)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
